{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:23:30.699345Z","iopub.execute_input":"2025-06-13T05:23:30.699591Z","iopub.status.idle":"2025-06-13T05:23:30.703017Z","shell.execute_reply.started":"2025-06-13T05:23:30.699575Z","shell.execute_reply":"2025-06-13T05:23:30.702305Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"**Lab-1**\n\nTasks to be performed:\n\na. Implement a descriptive Question answering System (Like\nChatGPT/Gemini) using NLG by utilizing the LLM Models (any\nfoundation model can use).\n\nb. While testing the Model, Understand the concept of Prompt\nEngineering, Optimization of the Prompt and Understand the impact\nof prompt formulation on model output. (Give all the insights as an\nexample in the Colab file)\n\nc. Enter any 3 the same prompt in your model, Gemini and ChatGPT and\nretrieve the answer and upload. Understand the difference of prompt\nin each model (as shown the following Gemini and ChatGPT).\n\nd. Upload any 3 the sample question and answers that you have\ngenerated (in Colab file).","metadata":{}},{"cell_type":"markdown","source":"Loading the FLAN-T5 Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\n\n# Model ID and device\nmodel_id = \"google/flan-t5-large\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load tokenizer and model, move model to GPU\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:23:30.704189Z","iopub.execute_input":"2025-06-13T05:23:30.704710Z","iopub.status.idle":"2025-06-13T05:23:33.161317Z","shell.execute_reply.started":"2025-06-13T05:23:30.704687Z","shell.execute_reply":"2025-06-13T05:23:33.160678Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"Prompt 1:  *prompt = f\"Answer this question in a descriptive and simple way:\\n{user_input}\"*","metadata":{}},{"cell_type":"code","source":"def descriptive_qa_chatbot():\n    print(\"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\\n\")\n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() == \"exit\":\n            print(\"Chatbot: Goodbye! ðŸ‘‹\")\n            break\n\n        prompt = f\"Answer this question in a descriptive and simple way:\\n{user_input}\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n        outputs = model.generate(**inputs, max_length=256,min_length=50, temperature=0.7, top_p=0.9, do_sample=True)\n        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        print(f\"Chatbot: {response}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:25:44.105933Z","iopub.execute_input":"2025-06-13T05:25:44.106485Z","iopub.status.idle":"2025-06-13T05:25:44.111408Z","shell.execute_reply.started":"2025-06-13T05:25:44.106458Z","shell.execute_reply":"2025-06-13T05:25:44.110753Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"descriptive_qa_chatbot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:25:54.334068Z","iopub.execute_input":"2025-06-13T05:25:54.334781Z","iopub.status.idle":"2025-06-13T05:26:21.935508Z","shell.execute_reply.started":"2025-06-13T05:25:54.334754Z","shell.execute_reply":"2025-06-13T05:26:21.934798Z"}},"outputs":[{"name":"stdout","text":"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  explain Ai\n"},{"name":"stdout","text":"Chatbot: explain Ai                                                                                                                              \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  explain AI\n"},{"name":"stdout","text":"Chatbot: Artificial intelligence is the science of artificial intelligence, computer science, and related fields. It is a technology that is used to perform a variety of tasks, such as performing mathematical computations. Artificial intelligence has been around for many years, and it has been used to explain many things.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"},{"name":"stdout","text":"Chatbot: Goodbye! ðŸ‘‹\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"prompt-2:","metadata":{}},{"cell_type":"code","source":"def descriptive_qa_chatbot():\n    print(\"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\\n\")\n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() == \"exit\":\n            print(\"Chatbot: Goodbye! ðŸ‘‹\")\n            break\n\n        prompt = f\"Explain like Iâ€™m 5 years old:\\n{user_input}\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n        outputs = model.generate(**inputs, max_length=256,min_length=50, temperature=0.7, top_p=0.9, do_sample=True)\n        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        print(f\"Chatbot: {response}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:24:27.916691Z","iopub.execute_input":"2025-06-13T05:24:27.916906Z","iopub.status.idle":"2025-06-13T05:24:27.921905Z","shell.execute_reply.started":"2025-06-13T05:24:27.916888Z","shell.execute_reply":"2025-06-13T05:24:27.921315Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"descriptive_qa_chatbot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:24:27.922695Z","iopub.execute_input":"2025-06-13T05:24:27.922944Z","iopub.status.idle":"2025-06-13T05:24:45.452840Z","shell.execute_reply.started":"2025-06-13T05:24:27.922922Z","shell.execute_reply":"2025-06-13T05:24:45.452094Z"}},"outputs":[{"name":"stdout","text":"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  explain AI\n"},{"name":"stdout","text":"Chatbot: AI is a machine intelligence system that is programmed to perform a number of tasks. Examples of tasks include: â€“ Identify the differences between humans and other animals â€“ Identify the difference between humans and other animals â€“ Identify the differences between humans and other animals\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"},{"name":"stdout","text":"Chatbot: Goodbye! ðŸ‘‹\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def descriptive_qa_chatbot():\n    print(\"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\\n\")\n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() == \"exit\":\n            print(\"Chatbot: Goodbye! ðŸ‘‹\")\n            break\n\n        prompt = f\"Answer the following question with a real-world example:\\n{user_input}\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n        outputs = model.generate(**inputs,max_length=256, min_length=50, temperature=0.7, top_p=0.9, do_sample=True)\n        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        print(f\"Chatbot: {response}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:24:45.453672Z","iopub.execute_input":"2025-06-13T05:24:45.453884Z","iopub.status.idle":"2025-06-13T05:24:45.459073Z","shell.execute_reply.started":"2025-06-13T05:24:45.453868Z","shell.execute_reply":"2025-06-13T05:24:45.458196Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"descriptive_qa_chatbot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:24:45.459969Z","iopub.execute_input":"2025-06-13T05:24:45.460271Z","iopub.status.idle":"2025-06-13T05:25:02.908032Z","shell.execute_reply.started":"2025-06-13T05:24:45.460248Z","shell.execute_reply":"2025-06-13T05:25:02.907407Z"}},"outputs":[{"name":"stdout","text":"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  explain AI\n"},{"name":"stdout","text":"Chatbot: Whenever we use the word \"AI\" in a sentence, we mean a computer. Computers are computer programs that can do many things. One example of computer program is artificial intelligence. A computer can make predictions about the future.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"},{"name":"stdout","text":"Chatbot: Goodbye! ðŸ‘‹\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def descriptive_qa_chatbot():\n    print(\"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\\n\")\n    while True:\n        user_input = input(\"You: \")\n        if user_input.lower() == \"exit\":\n            print(\"Chatbot: Goodbye! ðŸ‘‹\")\n            break\n\n        prompt = f\"Explain the following concept in detail using real-world examples, analogies, and multiple sentences:\\n{user_input}\"\n\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n        outputs = model.generate(**inputs, max_length=512, min_length=50, temperature=0.7, top_p=0.9, do_sample=True)\n        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        print(f\"Chatbot: {response}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:25:02.909094Z","iopub.execute_input":"2025-06-13T05:25:02.909370Z","iopub.status.idle":"2025-06-13T05:25:02.914230Z","shell.execute_reply.started":"2025-06-13T05:25:02.909346Z","shell.execute_reply":"2025-06-13T05:25:02.913553Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"descriptive_qa_chatbot()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:25:02.914877Z","iopub.execute_input":"2025-06-13T05:25:02.915118Z","iopub.status.idle":"2025-06-13T05:25:30.762586Z","shell.execute_reply.started":"2025-06-13T05:25:02.915101Z","shell.execute_reply":"2025-06-13T05:25:30.761853Z"}},"outputs":[{"name":"stdout","text":"ðŸ§  Descriptive Q&A Chatbot (type 'exit' to quit)\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  explain AI\n"},{"name":"stdout","text":"Chatbot: Artificial intelligence (AI) is a technology that can process information and create new knowledge. It is also used to design new products and services. It can help create new ways of thinking and making decisions. It can help in the manufacturing process, and in the production of goods and services.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  exit\n"},{"name":"stdout","text":"Chatbot: Goodbye! ðŸ‘‹\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"###  (b) Prompt Insights\n\n\n| Prompt | Notes |\n|--------|-------|\n| Answer this question in a descriptive and simple way| generic |\n| Explain like Iâ€™m 5 years old  |  vague |\n| Answer the following question with a real-world example  | incorrect |\n| Explain the following concept in detail using real-world examples, analogies, and multiple sentences | Super simplified |\n\n**Insights:**\n- More specific instructions = better quality output\n\n- The model responds differently depending on how instructions are framed.","metadata":{}},{"cell_type":"markdown","source":"![https://miro.medium.com/v2/resize:fit:1100/format:webp/0*Be1hO7QeqqsaGAhC.jpg](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*L5aMSNeQnIelxZEp8xMvqA.png)","metadata":{}},{"cell_type":"markdown","source":"image reference: https://medium.com/red-buffer/building-a-simple-chatbot-with-llm-719a37659d30","metadata":{}}]}